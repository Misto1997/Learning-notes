AL structure and tech overview

1.	CARMA(Client Account Relationship Master) is a application, that basically allow stakeholders & client to perform varies use cases like 
	-client onboarding(COB)/client creations,its lifecycle
	-concept of prospect (A prospectus is a formal document that is required by and filed with the Securities and Exchange Commission (SEC) 
		that provides details about an investment offering for sale to the public. ... A prospectus is used to help investors make a more
		informed investment decision).
	-and also assist you with some other domain like leads,client,accounts, households,relationships etc.
	- it is basically involved around whole wealth management system.
	-It is event based microservice that is again build based on 
		-domain driven design(DDD) so that it stays close to business process as it is based on core domains.
		-Command Query Responsibility Segregation (CQRS) in order to logically divide this into two system, one to provide read and one to provide write.
		-event sourcing o that all domain events direct represents the business facts.
	
2.	We have AGGR Kafka consumer(spring boot app.) that pulls data from kafka topic i.e(Carma,dash etc), do some business logic and saves it to brutusDB and 
	it runs on AWS/ECS(Elastic Container Service, used to run containers like docker).
	-there is one consumer per topic
	-
	
3.	We have AGGR ETL(Extract Transform Load) scripts (written in scala) that reads BPSA data from S3(Simplified Storage Service, storage and manage data) bucket 
	transform it and saves in brutusDB and it runs in aws glue(to manage ETL jobs and setups other things related to spark).
	-this runs once a day during night time to get data from s3 like(accounts,balances,positions etc that bpsa system contains).

4.	futher this burtus DB is been used by workstation team and some other teams.

5.	AGGR kafka consumer layer:-
	Transaction process:-
		-transaction data is coming from system called dash(broadridge side system) in TACT format.
		-these transactions are queued in kafka topics and then passed to EISL layer.
		-EISL(Enterprise Integration Service layer, uses ontology) is like middleware that transform the data format for us and transfer another kafka topic.
			-it converts that Tact format in json format and gives us that json format data to process.
		-kafka consumer takes this data process(updates,inserts etc) it and saves it to brutusDB.
		-all logs are kept in splunk so while processing if there is any error you check splunk for logs.
		
	for accounts and client info. the process is same but we get data from CARMA instead of Dash.
		-CARMA provides api's to get data
	
6.	AGGR ETL layer:-
	-Data will come from BPS(Brokerage Processing System) Layer from broadridge side, stored in s3 bucket and
	 it holds the main data like transaction,balances, security etc.
	-then this data is processed in aws glue in any manner required to business.
	-then its been saved to brutus DB and for this process we need to write scripts which validates each table,then read them,process them and stores it.
	-for each table we have corresponding valid table which stores the validated data in some different form or easier processable form.
	-process them means like join,filter etc.
	-brutus DB data is erased everyday and a fresh data is inserted from that s3 bucket to synchronized latest data.
	
7.	liquebase is used for versioning of database, its like git for dbms as you have to add, delete, update etc. tables and schema while developing.

8.	